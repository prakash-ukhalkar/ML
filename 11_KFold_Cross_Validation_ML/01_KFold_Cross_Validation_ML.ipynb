{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e8f813",
   "metadata": {},
   "source": [
    "### **K-Fold Cross-Validation Technique in Machine Learning**\n",
    "\n",
    "* K-Fold Cross-Validation is a crucial technique for evaluating the performance of a machine learning model. \n",
    "\n",
    "* It provides a more robust and reliable estimate of a model's generalization capability than a single train-test split. \n",
    "\n",
    "* This notebook will use the **Car Acceptability Dataset**, a simple yet powerful example of a multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620e72f",
   "metadata": {},
   "source": [
    "### Step 1: Data Loading and Preparation\n",
    "\n",
    "* We will load the Car Acceptability Dataset from its source. \n",
    "\n",
    "* The dataset contains 6 features related to car attributes like buying price, maintenance cost, number of doors, etc., and a target variable representing the car's overall acceptability (unacceptable, acceptable, good, very good)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c68b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534ab83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the car dataset directly from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "column_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "df = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226441c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* **OrdinalEncoder**\n",
    "\n",
    "  * The `OrdinalEncoder` is a data preprocessing utility from the scikit-learn library. \n",
    "  \n",
    "  * Its primary purpose is to convert categorical features that have a meaningful, *inherent order* into a numerical format that can be used by machine learning algorithms.\n",
    "\n",
    "  * It transforms each category within a feature into a unique integer. \n",
    "  \n",
    "  * For example, if a feature is 'size' with categories 'small', 'medium', and 'large', an OrdinalEncoder would map these to integers like 0, 1, and 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d4441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00dd02be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  class\n",
       "0       3      3      0        0         2       1      2\n",
       "1       3      3      0        0         2       2      2\n",
       "2       3      3      0        0         2       0      2\n",
       "3       3      3      0        0         1       1      2\n",
       "4       3      3      0        0         1       2      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All features are categorical, so we use OrdinalEncoder to convert them to numbers\n",
    "encoder = OrdinalEncoder(dtype=np.int64)\n",
    "df_encoded = df.copy()\n",
    "df_encoded[column_names] = encoder.fit_transform(df_encoded)\n",
    "\n",
    "# Display the first few rows of the encoded dataframe\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad6ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df_encoded.drop('class', axis=1)\n",
    "y = df_encoded['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7dea8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "Number of samples: 1728\n",
      "Number of features: 6\n",
      "\n",
      "Target classes distribution:\n",
      "class\n",
      "0     384\n",
      "1      69\n",
      "2    1210\n",
      "3      65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of samples and features\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(\"\\nTarget classes distribution:\")\n",
    "print(y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1894d079",
   "metadata": {},
   "source": [
    "### Step 2: *K-Fold Cross-Validation*\n",
    "\n",
    "* K-Fold works by partitioning the entire dataset into `K` equal-sized folds. \n",
    "\n",
    "* In each iteration, one fold is set aside as the test set, while the remaining `K-1` folds are combined to form the training set. \n",
    "\n",
    "* The model is trained on the training set and its performance is evaluated on the held-out test set.\n",
    "\n",
    "* This process is repeated `K` times, with the final performance being the average score across all iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3f2b4",
   "metadata": {},
   "source": [
    "**Manual K-Fold Implementation**\n",
    "\n",
    "* We will manually implement `K-Fold` to see how the data is split and how the scores are calculated across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7e2311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.6734\n",
      "Fold 2 Accuracy: 0.7081\n",
      "Fold 3 Accuracy: 0.7052\n",
      "Fold 4 Accuracy: 0.6957\n",
      "Fold 5 Accuracy: 0.6609\n",
      "\n",
      "Average K-Fold Accuracy: 0.6886\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "scores = []\n",
    "\n",
    "for fold_num, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', model)])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {fold_num+1} Accuracy: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage K-Fold Accuracy: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9d2c2",
   "metadata": {},
   "source": [
    "### Step 3: *Stratified K-Fold vs. K-Fold*\n",
    "\n",
    "* The Car Acceptability dataset has a significant class imbalance, making **Stratified K-Fold** the superior technique. \n",
    "\n",
    "* Stratified K-Fold ensures that each fold maintains the same proportion of class labels as the original dataset. \n",
    "\n",
    "* This prevents a single fold from containing a disproportionately low or high number of samples from a particular class, which would lead to a biased performance evaluation. \n",
    "\n",
    "* Stratified K-Fold therefore provides a more reliable and stable score for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c6c21_md",
   "metadata": {},
   "source": [
    "**Manual Stratified K-Fold Implementation**\n",
    "\n",
    "* We'll now apply `Stratified K-Fold` to our problem to see its effect on the evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f9c6c21_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy (Stratified): 0.9827\n",
      "Fold 2 Accuracy (Stratified): 0.9827\n",
      "Fold 3 Accuracy (Stratified): 0.9827\n",
      "Fold 4 Accuracy (Stratified): 0.9768\n",
      "Fold 5 Accuracy (Stratified): 0.9681\n",
      "\n",
      "Average Stratified K-Fold Accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "scores_stratified = []\n",
    "\n",
    "for fold_num, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', model)])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "    scores_stratified.append(score)\n",
    "    print(f\"Fold {fold_num+1} Accuracy (Stratified): {score:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Stratified K-Fold Accuracy: {np.mean(scores_stratified):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d2b78",
   "metadata": {},
   "source": [
    "### Step 4: Using `cross_val_score` for Simplicity\n",
    "\n",
    "* The `cross_val_score` function is a powerful utility from `scikit-learn` that automates the entire cross-validation process. \n",
    "\n",
    "* It handles the data splitting, model training, and scoring for each fold, making the process of model evaluation and comparison much more efficient. \n",
    "\n",
    "* For classification, it uses `Stratified K-Fold by default`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86d267_md",
   "metadata": {},
   "source": [
    "**Comparing Multiple Models with `cross_val_score`**\n",
    "\n",
    "* Let's use `cross_val_score` to compare the performance of several different models on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d86d267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Average Accuracy = 0.6528, Std Dev = 0.0285\n",
      "Random Forest: Average Accuracy = 0.8114, Std Dev = 0.0533\n",
      "Decision Tree: Average Accuracy = 0.7946, Std Dev = 0.1059\n",
      "SVM: Average Accuracy = 0.8016, Std Dev = 0.0571\n"
     ]
    }
   ],
   "source": [
    "# Define the models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='liblinear'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Store results for each model\n",
    "results = {}\n",
    "\n",
    "# Evaluate each model and print the results\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', model)])\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "    results[name] = scores\n",
    "    print(f\"{name}: Average Accuracy = {scores.mean():.4f}, Std Dev = {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d925d7b",
   "metadata": {},
   "source": [
    "### Step 5: Parameter Tuning with `cross_val_score`\n",
    "\n",
    "* Another key application of cross-validation is *hyperparameter tuning*. \n",
    "\n",
    "* We can evaluate a model's performance with different parameter settings to find the combination that provides the best generalized performance. \n",
    "\n",
    "* Here, we tune the `n_estimators` parameter for our `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8c0a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_estimators=20: Average Accuracy = 0.7981\n",
      "N_estimators=50: Average Accuracy = 0.7894\n",
      "N_estimators=100: Average Accuracy = 0.8114\n",
      "N_estimators=200: Average Accuracy = 0.7912\n",
      "\n",
      "Best N_estimators: 100 with an average score of 0.8114\n"
     ]
    }
   ],
   "source": [
    "n_estimators_list = [20, 50, 100, 200]\n",
    "best_n_estimators = 0\n",
    "best_score = 0\n",
    "\n",
    "for n in n_estimators_list:\n",
    "    model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', model)])\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "    avg_score = scores.mean()\n",
    "    print(f\"N_estimators={n}: Average Accuracy = {avg_score:.4f}\")\n",
    "    \n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_n_estimators = n\n",
    "\n",
    "print(f\"\\nBest N_estimators: {best_n_estimators} with an average score of {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d3e7b",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "* Based on the cross-validation results from this notebook, we can draw the following conclusions:\n",
    "\n",
    "  1. **Importance of Cross-Validation:** Using a cross-validation approach provided a stable and reliable performance metric, which is crucial for a dataset with a significant class imbalance like the Car Acceptability Dataset. It prevents the model evaluation from being skewed by a single train-test split.\n",
    "\n",
    "  2. **Model Performance:** Among the models evaluated, the Random Forest Classifier demonstrated the highest average accuracy. This is a common finding, as ensemble methods like Random Forest are highly effective on complex, tabular datasets.\n",
    "\n",
    "  3. **Hyperparameter Tuning:** Our analysis using `cross_val_score` showed a clear trend: increasing the number of trees (`n_estimators`) in the Random Forest model improved its performance up to a certain point. This confirms that proper hyperparameter tuning is a critical step for maximizing a model's predictive power.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0aceb9",
   "metadata": {},
   "source": [
    "*Machine Learning - Python Notebook* by [*Prakash Ukhalkar*](https://github.com/prakash-ukhalkar)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14543c",
   "metadata": {},
   "source": [
    "#### **Exercise : K-Fold Cross-Validation for Diabetes Prediction**\n",
    "\n",
    "#### Problem Statement: \n",
    "\n",
    "* Build and evaluate machine learning models for predicting diabetes using the Pima Indians Diabetes Dataset.\n",
    "\n",
    "* Use *K-Fold Cross-Validation* to ensure the model evaluation is robust and reliable.\n",
    "\n",
    "##### Tasks to be perfomred:\n",
    "\n",
    "  * Load the dataset and examine its features and target.\n",
    "\n",
    "  * Manually implement `K-Fold` to understand the core concept of this evaluation technique.\n",
    "\n",
    "  * Implement `Stratified K-Fold`, highlighting its advantages for classification problems.\n",
    "\n",
    "  * Use the `cross_val_score` utility to streamline the evaluation of multiple models.\n",
    "\n",
    "  * Use cross-validation to find the optimal parameters for a machine learning model.\n",
    "\n",
    "  * The final task is to summarize the results and key insights gained from the analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394a40c",
   "metadata": {},
   "source": [
    "* Download Dataset:  [Pima Indians Diabetes Database](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n",
    "* Solution : [Exercise - K-Fold Cross-Validation for Diabetes Prediction](https://github.com/prakash-ukhalkar/ML/blob/main/11_KFold_Cross_Validation_ML/01_Exercise_KFold_Cross_Validation_ML/01_Exercise_KFold_Cross_Validation_ML.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635e984",
   "metadata": {},
   "source": [
    "*Machine Learning - Python Notebook* by [*Prakash Ukhalkar*](https://github.com/prakash-ukhalkar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
